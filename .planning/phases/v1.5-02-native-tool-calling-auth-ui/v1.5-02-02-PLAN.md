---
phase: v1.5-02-native-tool-calling-auth-ui
plan: 02
type: execute
wave: 2
depends_on: ["v1.5-02-01"]
files_modified:
  - nexus/packages/core/src/agent.ts
  - nexus/packages/core/src/brain.ts
  - nexus/packages/core/src/providers/manager.ts
autonomous: true

must_haves:
  truths:
    - "When Claude is the active provider, the AgentLoop uses native tool_use blocks instead of JSON-in-text parsing"
    - "When Gemini is the active provider (fallback), the AgentLoop uses existing JSON-in-text parseStep() parsing"
    - "Claude tool_use_id is tracked and included in tool_result messages sent back to Claude"
    - "Multiple tool_use blocks in a single Claude response are executed sequentially and all results returned"
    - "Extended thinking blocks from Claude are emitted as 'thinking' AgentEvents with the reasoning content"
  artifacts:
    - path: "nexus/packages/core/src/agent.ts"
      provides: "Dual-mode AgentLoop with native tool calling for Claude and JSON-in-text for Gemini"
      contains: "tool_use"
    - path: "nexus/packages/core/src/brain.ts"
      provides: "Brain.chatStream() and Brain.chat() pass tools through to provider, return tool call results"
      contains: "tools"
    - path: "nexus/packages/core/src/providers/manager.ts"
      provides: "ProviderManager passes tools through to active provider"
      contains: "tools"
  key_links:
    - from: "nexus/packages/core/src/agent.ts"
      to: "nexus/packages/core/src/brain.ts"
      via: "brain.chatStream({...options, tools}) returns stream chunks with toolUse blocks"
      pattern: "tools.*toClaudeTools"
    - from: "nexus/packages/core/src/brain.ts"
      to: "nexus/packages/core/src/providers/manager.ts"
      via: "manager.chatStream({...options, tools}) delegates to active provider"
      pattern: "tools"
    - from: "nexus/packages/core/src/agent.ts"
      to: "nexus/packages/core/src/tool-registry.ts"
      via: "toolRegistry.toClaudeToolsFiltered(toolPolicy) generates tool definitions"
      pattern: "toClaudeToolsFiltered"
---

<objective>
Implement dual-mode tool calling in the AgentLoop: when Claude is the active provider, use native tool_use content blocks with proper tool_use_id tracking; when Gemini is the fallback, preserve existing JSON-in-text parseStep() behavior. Handle multiple tool_use blocks per response. Emit extended thinking content as AgentEvents.

Purpose: This is the core feature of Phase 2 — making the AI agent use Claude's native tool calling for reliable, structured tool execution while maintaining Gemini compatibility.

Output: AgentLoop that detects provider type and uses the appropriate tool calling mechanism. Brain/ProviderManager pass tools through. All existing callers remain unchanged.
</objective>

<execution_context>
@C:\Users\hello\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\hello\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/STATE.md
@.planning/ROADMAP.md

# Phase 1 outputs
@.planning/phases/v1.5-01-provider-abstraction-claude/v1.5-01-03-SUMMARY.md

# Plan 01 output (will be executed before this plan)
@.planning/phases/v1.5-02-native-tool-calling-auth-ui/v1.5-02-01-PLAN.md

# Source files to modify
@nexus/packages/core/src/agent.ts
@nexus/packages/core/src/brain.ts
@nexus/packages/core/src/providers/manager.ts
@nexus/packages/core/src/providers/types.ts
@nexus/packages/core/src/tool-registry.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Thread tools through Brain and ProviderManager, expose provider info</name>
  <files>
    nexus/packages/core/src/brain.ts
    nexus/packages/core/src/providers/manager.ts
  </files>
  <action>
**Goal:** Allow the AgentLoop to pass Claude tool definitions through Brain -> ProviderManager -> Provider, and to know which provider is active so it can choose the right tool calling mode.

**In `nexus/packages/core/src/brain.ts`:**

1. Update the `ChatOptions` interface to include an optional `tools` field:
```typescript
interface ChatOptions {
  systemPrompt: string;
  messages: ChatMessage[];
  tier?: ModelTier;
  maxTokens?: number;
  /** Claude tool definitions for native tool calling */
  tools?: import('./providers/types.js').ClaudeToolDefinition[];
}
```

2. Update `chat()` to pass tools through:
```typescript
async chat(options: ChatOptions): Promise<{ text: string; inputTokens: number; outputTokens: number; toolCalls?: import('./providers/types.js').ToolUseBlock[]; stopReason?: string }> {
  const normalized = normalizeMessages(options.messages);
  const result = await this.manager.chat({
    systemPrompt: options.systemPrompt,
    messages: normalized,
    tier: options.tier,
    maxOutputTokens: options.maxTokens,
    tools: options.tools,
  });
  return {
    text: result.text,
    inputTokens: result.inputTokens,
    outputTokens: result.outputTokens,
    toolCalls: result.toolCalls,
    stopReason: result.stopReason,
  };
}
```

3. Update `chatStream()` to pass tools through:
```typescript
chatStream(options: ChatOptions): ChatStreamResult {
  const normalized = normalizeMessages(options.messages);
  const result = this.manager.chatStream({
    systemPrompt: options.systemPrompt,
    messages: normalized,
    tier: options.tier,
    maxOutputTokens: options.maxTokens,
    tools: options.tools,
  });
  return {
    stream: result.stream,
    getUsage: result.getUsage,
  };
}
```

4. Add a method to get the active provider ID:
```typescript
/** Get the ID of the primary available provider ('claude' or 'gemini') */
async getActiveProviderId(): Promise<string> {
  const providers = await this.manager.listProviders();
  const available = providers.find(p => p.available);
  return available?.id || 'gemini';
}
```

**In `nexus/packages/core/src/providers/manager.ts`:**

The ProviderManager.chat() and chatStream() already pass the full `ProviderChatOptions` through to the provider. Since we added `tools` to `ProviderChatOptions` in Plan 01, this should work automatically. Verify that the `options` object is passed directly (not destructured without tools).

Check the existing code: `const result = await provider.chat(options)` — yes, the full options object is passed. Same for chatStream: `const result = provider.chatStream(options)`. No changes needed to manager.ts if tools are already in ProviderChatOptions.

BUT: Update `ProviderStreamResult` to include a way to get the active provider. Actually, it already has `provider` and `model` fields. The AgentLoop needs to know the provider BEFORE starting the stream so it can decide whether to use tool calling mode. Add a method:

```typescript
/** Get the first available provider ID without making an API call */
async getActiveProviderId(): Promise<string | null> {
  for (const providerId of this.fallbackOrder) {
    const provider = this.providers.get(providerId);
    if (!provider) continue;
    const available = await provider.isAvailable();
    if (available) return providerId;
  }
  return null;
}
```
  </action>
  <verify>
Run `cd nexus && npx tsc --noEmit` — zero errors. Verify brain.ts chat() and chatStream() accept `tools` option. Verify brain.ts has `getActiveProviderId()` method.
  </verify>
  <done>
Brain.chat() and Brain.chatStream() pass tools through to ProviderManager. Brain.chat() returns toolCalls and stopReason from the provider. Brain and ProviderManager expose getActiveProviderId() for the AgentLoop to detect which provider is active.
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement dual-mode AgentLoop with native Claude tool calling and Gemini fallback</name>
  <files>
    nexus/packages/core/src/agent.ts
  </files>
  <action>
This is the core task. The AgentLoop must detect the active provider and use either:
- **Claude mode**: Send tools via native API, receive tool_use blocks, send tool_result blocks
- **Gemini mode**: Use existing JSON-in-text parseStep() with the AGENT_SYSTEM_PROMPT

**Changes to `agent.ts`:**

1. **Add imports** at the top:
```typescript
import type { ClaudeToolDefinition, ToolUseBlock, ToolResultBlock } from './providers/types.js';
```

2. **At the start of `run()` method**, detect the active provider and prepare tools:
```typescript
// Detect active provider for tool calling mode
const activeProvider = await brain.getActiveProviderId();
const useNativeTools = activeProvider === 'claude';

// Prepare Claude tool definitions if using native tool calling
let claudeTools: ClaudeToolDefinition[] | undefined;
if (useNativeTools) {
  claudeTools = toolRegistry.toClaudeToolsFiltered(toolPolicy);
  // Only use native tools if there are tools registered
  if (claudeTools.length === 0) claudeTools = undefined;
}
```

3. **Modify the system prompt for Claude mode**. When using native tool calling, Claude does NOT need the JSON-in-text instructions. Replace the system prompt construction:

```typescript
// Build system prompt — different for Claude (native tools) vs Gemini (JSON-in-text)
let systemPrompt: string;
if (this.config.systemPromptOverride) {
  systemPrompt = this.config.systemPromptOverride;
} else if (useNativeTools && claudeTools) {
  // Claude with native tool calling — simpler prompt, no JSON format instructions
  systemPrompt = CLAUDE_NATIVE_SYSTEM_PROMPT(canSpawnSubagent);
} else {
  // Gemini or Claude without tools — use existing JSON-in-text prompt
  systemPrompt = AGENT_SYSTEM_PROMPT(toolDescriptions, canSpawnSubagent);
}
```

4. **Create CLAUDE_NATIVE_SYSTEM_PROMPT** function (add before the class):

```typescript
const CLAUDE_NATIVE_SYSTEM_PROMPT = (canSpawnSubagent: boolean) => `You are Nexus, an autonomous AI assistant. You manage a Linux server AND interact with the user via WhatsApp. You solve tasks by reasoning step-by-step and calling tools.

## WhatsApp Context

You are integrated into the user's WhatsApp. When the user sends a command (prefixed with "!"), you receive it along with recent chat history from that conversation. This history includes:
- Messages from contacts (shown as "ContactName: message") — these are REAL messages from other people in the chat
- Messages from the user (shown as "User: message")
- Your previous responses (shown as "Nexus: message")

You CAN see and reference this chat context. If the user asks about what someone said, use the provided conversation history to answer.

IMPORTANT: When the user asks you to send a message to a SPECIFIC person, use the whatsapp_send tool with the contact name.

## How You Work

You have access to tools. Use them to accomplish the user's task:
1. Think about what you need to do
2. Call the appropriate tool(s) to accomplish it
3. When the task is complete, provide your final answer as a text response (no tool call)

## Rules

1. Think before acting
2. Call ONE tool per turn, then observe the result before deciding next step
3. If a tool fails, try a different approach
4. When the task is complete, provide your final answer as text
5. Be concise in your final answer
${canSpawnSubagent ? `6. For complex subtasks, use spawn_subagent to delegate to a focused subagent` : ''}

## Browser Safety (CRITICAL)

When using Chrome browser tools (mcp_chrome_browser_*):
- NEVER interact with login/sign-in pages, password fields, or authentication flows
- NEVER click "Sign in", "Log in", "Sign out", or account-related buttons
- If a page requires authentication, STOP and tell the user to sign in manually

## Memory

You have long-term memory via memory_search and memory_add tools:
- When the user asks about something from past conversations, use memory_search FIRST
- When you learn important facts or preferences, use memory_add to save them`;
```

5. **In the main agent loop**, add a branch based on `useNativeTools`:

After the streaming/non-streaming brain call, instead of always calling `this.parseStep(responseText)`, check if we received native tool calls:

```typescript
// === CLAUDE NATIVE TOOL CALLING MODE ===
if (useNativeTools && claudeTools) {
  // Streaming mode with native tools
  if (streaming) {
    const { stream, getUsage } = brain.chatStream({
      systemPrompt,
      messages,
      tier,
      maxTokens: 4096,
      tools: claudeTools,
    });

    const textChunks: string[] = [];
    const toolUseBlocks: ToolUseBlock[] = [];
    let lastStopReason = '';

    for await (const chunk of stream) {
      if (chunk.text) {
        textChunks.push(chunk.text);
        this.emitEvent({ type: 'chunk', turn: turn + 1, data: chunk.text });
      }
      if (chunk.toolUse) {
        toolUseBlocks.push(chunk.toolUse);
      }
      if (chunk.stopReason) {
        lastStopReason = chunk.stopReason;
      }
    }

    responseText = textChunks.join('');
    const usage = getUsage();
    totalInputTokens += usage.inputTokens;
    totalOutputTokens += usage.outputTokens;

    // Determine if this is a tool call or final answer based on stop_reason and tool_use blocks
    if (toolUseBlocks.length > 0) {
      // Process each tool call
      // ... (see tool execution logic below)
    } else {
      // Final answer — no tool calls
      // ... (emit final_answer and return)
    }
  }
  // Similar for non-streaming mode using brain.chat() with tools
}
```

6. **Tool execution for native tool calling**:

When tool_use blocks are received, execute each tool and build tool_result messages:

```typescript
if (toolUseBlocks.length > 0) {
  // Log the thinking text (if any) as reasoning
  if (responseText.trim()) {
    this.emitEvent({ type: 'thinking', turn: turn + 1, data: responseText });
  }

  // Add assistant message with the full response to conversation history
  // For Claude, the assistant message must include both text and tool_use blocks
  messages.push({
    role: 'model',
    text: responseText,
    // Store tool calls metadata for reconstruction when sending back to Claude
    _toolCalls: toolUseBlocks,
  } as any);

  // Execute each tool and collect results
  const toolResults: ToolResultBlock[] = [];
  for (const toolCall of toolUseBlocks) {
    this.emitEvent({
      type: 'tool_call',
      turn: turn + 1,
      data: { tool: toolCall.name, params: toolCall.input, thought: responseText.slice(0, 200) },
    });

    // Fire onAction callback
    if (this.config.onAction) {
      try {
        this.config.onAction({
          type: 'tool_call',
          tool: toolCall.name,
          params: toolCall.input,
          thought: responseText.slice(0, 200),
          turn: turn + 1,
        });
      } catch { /* don't let callback errors break the agent loop */ }
    }

    let toolResult: ToolResult;
    if (!toolRegistry.isToolAllowed(toolCall.name, toolPolicy)) {
      toolResult = { success: false, output: '', error: `Tool "${toolCall.name}" is not allowed by the current policy.` };
    } else if (toolCall.name === 'spawn_subagent' && canSpawnSubagent) {
      toolResult = await this.spawnSubagent(toolCall.input, depth);
    } else if (toolCall.name === 'spawn_subagent' && !canSpawnSubagent) {
      toolResult = { success: false, output: '', error: `Maximum subagent depth (${maxDepth}) reached.` };
    } else {
      toolResult = await toolRegistry.execute(toolCall.name, toolCall.input);
    }

    toolCalls.push({ tool: toolCall.name, params: toolCall.input, result: toolResult });

    const resultContent = toolResult.success
      ? toolResult.output
      : `Error: ${toolResult.error || toolResult.output}`;

    toolResults.push({
      type: 'tool_result',
      tool_use_id: toolCall.id,
      content: resultContent,
      is_error: !toolResult.success,
    });

    this.emitEvent({
      type: 'observation',
      turn: turn + 1,
      data: { tool: toolCall.name, success: toolResult.success, output: (toolResult.output || '').slice(0, 500) },
    });

    // Fire onAction with result
    if (this.config.onAction) {
      try {
        this.config.onAction({
          type: 'tool_call',
          tool: toolCall.name,
          params: toolCall.input,
          thought: responseText.slice(0, 200),
          success: toolResult.success,
          output: (toolResult.output || '').slice(0, 200),
          turn: turn + 1,
        });
      } catch { /* don't let callback errors break the agent loop */ }
    }
  }

  // Add tool results as user message
  // For Claude, tool_result blocks go in the user message
  const toolResultText = toolResults.map(r =>
    `Tool "${toolUseBlocks.find(t => t.id === r.tool_use_id)?.name}": ${r.content}`
  ).join('\n\n');

  messages.push({
    role: 'user',
    text: toolResultText,
    _toolResults: toolResults,
  } as any);

  // Continue to next turn
  continue;
}
```

7. **Handle final answer in Claude native mode**:

When there are no tool_use blocks (stop_reason is 'end_turn' or 'max_tokens'):

```typescript
// No tool calls — this is the final answer
messages.push({ role: 'model', text: responseText });
this.emitEvent({ type: 'final_answer', turn: turn + 1, data: responseText });
if (this.config.onAction) {
  try {
    this.config.onAction({ type: 'final_answer', turn: turn + 1, answer: responseText });
  } catch { /* don't let callback errors break the agent loop */ }
}
return {
  success: true,
  answer: responseText,
  turns: turn + 1,
  totalInputTokens,
  totalOutputTokens,
  toolCalls,
  stoppedReason: 'complete',
};
```

8. **Update the message normalization for Claude tool calls**:

The `_toolCalls` and `_toolResults` metadata stored on messages need to be converted when sent to Claude. Update `nexus/packages/core/src/providers/normalize.ts` — actually NO, don't modify normalize.ts. Instead, in `nexus/packages/core/src/providers/claude.ts`, update `prepareForProvider` to handle these extra fields. BUT that would require changing the shared normalize.ts.

**Better approach**: In `brain.ts`, when converting messages for the provider, check for `_toolCalls` and `_toolResults` metadata and construct the proper Claude content blocks. This means the Brain.chatStream/chat needs to handle this conversion.

Actually, the simplest approach: add a new function in `normalize.ts` called `prepareMessagesWithToolCalls()` that the ClaudeProvider can use when tools are present. This function converts:
- Messages with `_toolCalls` metadata into assistant messages with content: [TextBlock, ...ToolUseBlock]
- Messages with `_toolResults` metadata into user messages with content: [...ToolResultBlock]

Add to `normalize.ts`:
```typescript
/**
 * Prepare messages for Claude with native tool call history.
 * Handles _toolCalls and _toolResults metadata on messages.
 */
export function prepareForClaudeWithTools(
  messages: ProviderMessage[],
): Anthropic.MessageParam[] {
  // ... implementation
}
```

Wait — normalize.ts doesn't import Anthropic types. Keep it simpler: have the conversion happen in `agent.ts` itself before passing to brain. The agent constructs proper ProviderMessage arrays with content blocks inline.

**Simplest correct approach**: Store tool calls and results as part of the message text, but in the `providerOptions` or as a separate field. When `useNativeTools` is true, the AgentLoop constructs the messages differently.

Actually the most pragmatic approach: When `useNativeTools` is true, the AgentLoop manages its own message array that contains raw Claude-compatible message objects (with content blocks), and passes these via a new `rawMessages` option that bypasses normalization. This avoids polluting the generic ChatMessage type.

Let me take a step back. The cleanest implementation:

**Add a `rawClaudeMessages` field to ChatOptions in brain.ts** that bypasses normalization:

```typescript
interface ChatOptions {
  systemPrompt: string;
  messages: ChatMessage[];
  tier?: ModelTier;
  maxTokens?: number;
  tools?: ClaudeToolDefinition[];
  /** Pre-formatted Claude messages (bypasses normalization, used for tool_result messages) */
  rawClaudeMessages?: any[];
}
```

In Brain.chat/chatStream, if `rawClaudeMessages` is provided, pass those directly instead of normalizing:

```typescript
chatStream(options: ChatOptions): ChatStreamResult {
  const messages = options.rawClaudeMessages
    ? options.rawClaudeMessages
    : normalizeMessages(options.messages);
  // ... pass to manager
}
```

Then in the AgentLoop, when in Claude native mode, maintain a parallel `claudeMessages` array alongside the generic `messages` array. The `claudeMessages` array contains proper Claude content blocks with tool_use and tool_result.

**Final implementation approach for agent.ts**:

In the `run()` method, when `useNativeTools` is true:
- Maintain a `claudeMessages: any[]` array for Claude-specific message formatting
- When the assistant responds with tool_use blocks, push an assistant message with `content: [{type: 'text', text: ...}, ...toolUseBlocks]`
- When tool results come back, push a user message with `content: toolResults.map(r => ({type: 'tool_result', tool_use_id: r.tool_use_id, content: r.content}))`
- Pass these via `rawClaudeMessages` to brain.chatStream/chat

This keeps the existing ChatMessage[] for Gemini compatibility and adds a parallel array for Claude.

Implement this in the dual-mode section of the agent loop. The key structures:

```typescript
// Parallel Claude message array (only used when useNativeTools is true)
const claudeMessages: any[] = [];

// Initial user message
if (useNativeTools) {
  claudeMessages.push({ role: 'user', content: taskWithContext });
}

// After receiving response with tool calls:
if (useNativeTools) {
  const contentBlocks: any[] = [];
  if (responseText) contentBlocks.push({ type: 'text', text: responseText });
  for (const tc of toolUseBlocks) {
    contentBlocks.push({ type: 'tool_use', id: tc.id, name: tc.name, input: tc.input });
  }
  claudeMessages.push({ role: 'assistant', content: contentBlocks });

  // Tool results
  const resultBlocks = toolResults.map(r => ({
    type: 'tool_result',
    tool_use_id: r.tool_use_id,
    content: r.content,
    ...(r.is_error ? { is_error: true } : {}),
  }));
  claudeMessages.push({ role: 'user', content: resultBlocks });
}

// When calling brain:
brain.chatStream({
  systemPrompt,
  messages, // still needed for generic tracking
  tier,
  maxTokens: 4096,
  tools: claudeTools,
  rawClaudeMessages: useNativeTools ? claudeMessages : undefined,
});
```

9. **Handle extended thinking**: If the response contains `thinking` content blocks (when extended thinking is enabled via providerOptions), emit them as thinking events:

```typescript
// In the streaming loop, check for thinking blocks:
if (event.type === 'content_block_start' && event.content_block.type === 'thinking') {
  // Start accumulating thinking text
}
if (event.type === 'content_block_delta' && event.delta.type === 'thinking_delta') {
  // Emit thinking event
  this.emitEvent({ type: 'thinking', turn: turn + 1, data: event.delta.thinking });
}
```

This requires extending `ProviderStreamChunk` to carry thinking text. Add a `thinking?: string` field to ProviderStreamChunk in types.ts, and handle it in ClaudeProvider.chatStream(). The AgentLoop then emits `type: 'thinking'` events.

NOTE: Extended thinking requires `anthropic-beta: output-128k-2025-02-19` header and budget_tokens config. For now, just handle the content blocks IF they appear. Don't enable extended thinking by default — that can be a follow-up.

10. **Preserve the EXISTING Gemini code path**: The entire existing code (parseStep, AGENT_SYSTEM_PROMPT, JSON-in-text) stays intact. When `useNativeTools` is false, the agent loop executes exactly as before. Wrap the native tool calling logic in `if (useNativeTools && claudeTools) { ... } else { /* existing code */ }`.
  </action>
  <verify>
1. `cd nexus && npx tsc --noEmit` — zero errors
2. Verify agent.ts has `useNativeTools` branching logic
3. Verify agent.ts has `CLAUDE_NATIVE_SYSTEM_PROMPT`
4. Verify agent.ts handles `toolUseBlocks` from streaming
5. Verify agent.ts constructs `claudeMessages` with tool_use and tool_result content blocks
6. Verify brain.ts accepts and passes through `rawClaudeMessages`
7. Verify the existing Gemini code path is unchanged (parseStep still exists and is used)
  </verify>
  <done>
AgentLoop detects active provider via brain.getActiveProviderId(). Claude mode: uses native tool_use blocks, tracks tool_use_id, sends tool_result in proper content block format, uses simplified system prompt without JSON format instructions. Gemini mode: existing JSON-in-text parseStep() unchanged. Multiple tool calls per response handled sequentially. Extended thinking blocks emitted as AgentEvents. TypeScript compiles cleanly.
  </done>
</task>

</tasks>

<verification>
1. `cd nexus && npx tsc --noEmit` compiles with zero errors
2. The AgentLoop has two distinct code paths: native tool calling (Claude) and JSON-in-text (Gemini)
3. `grep -n "useNativeTools" nexus/packages/core/src/agent.ts` shows the branching
4. `grep -n "tool_use_id" nexus/packages/core/src/agent.ts` shows ID tracking
5. `grep -n "rawClaudeMessages" nexus/packages/core/src/brain.ts` shows the passthrough
6. `grep -n "parseStep" nexus/packages/core/src/agent.ts` still exists (Gemini path preserved)
7. `grep -n "CLAUDE_NATIVE_SYSTEM_PROMPT" nexus/packages/core/src/agent.ts` shows the simplified prompt
</verification>

<success_criteria>
- AgentLoop detects Claude vs Gemini and uses appropriate tool calling mechanism
- Claude mode sends native tool definitions, receives tool_use blocks, returns tool_result blocks
- tool_use_id is tracked and included in tool_result messages
- Multiple tool_use blocks in one response are all executed
- Gemini mode preserves exact existing behavior (parseStep, AGENT_SYSTEM_PROMPT)
- Brain and ProviderManager pass tools and rawClaudeMessages through to provider
- Extended thinking content blocks are emitted as AgentEvents when present
- All existing callers (api.ts, daemon.ts, etc.) work without changes
- TypeScript compiles with zero errors
</success_criteria>

<output>
After completion, create `.planning/phases/v1.5-02-native-tool-calling-auth-ui/v1.5-02-02-SUMMARY.md`
</output>
