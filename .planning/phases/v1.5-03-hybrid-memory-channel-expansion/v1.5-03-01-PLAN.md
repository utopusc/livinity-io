---
phase: v1.5-03-hybrid-memory-channel-expansion
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - nexus/packages/memory/src/index.ts
  - nexus/packages/core/src/daemon.ts
autonomous: true

must_haves:
  truths:
    - "After a conversation ends, a BullMQ job automatically extracts important facts and stores them as memories"
    - "Duplicate memories are detected via embedding cosine similarity and merged instead of duplicated"
    - "Each memory is linked to the session/conversation that produced it via a memory_sessions table"
    - "Memory search results are scored with time-decay so recent memories rank higher than old ones"
  artifacts:
    - path: "nexus/packages/memory/src/index.ts"
      provides: "memory_sessions table, dedup endpoint, time-decay search"
      contains: "memory_sessions"
    - path: "nexus/packages/core/src/daemon.ts"
      provides: "BullMQ memory extraction job after conversation completion"
      contains: "memory-extraction"
  key_links:
    - from: "nexus/packages/core/src/daemon.ts"
      to: "http://localhost:3300/add"
      via: "BullMQ job after conversation completes"
      pattern: "memory-extraction"
    - from: "nexus/packages/memory/src/index.ts"
      to: "cosine similarity dedup"
      via: "embedding comparison before insert"
      pattern: "DEDUP_THRESHOLD"
---

<objective>
Add automatic memory extraction after conversations, deduplication via embedding similarity, session-to-memory binding, and time-decay scoring to the memory search.

Purpose: The AI should automatically remember important facts from conversations without requiring explicit "remember" commands. Duplicate facts should not accumulate, and recent memories should be prioritized.

Output: Enhanced memory service with automatic extraction pipeline, deduplication, session binding, and temporal scoring.
</objective>

<execution_context>
@C:\Users\hello\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\hello\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@nexus/packages/memory/src/index.ts
@nexus/packages/core/src/daemon.ts
@nexus/packages/core/src/schedule-manager.ts
@nexus/packages/core/src/session-manager.ts
@nexus/packages/core/src/brain.ts
@nexus/packages/core/src/index.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Enhance memory service with sessions table, dedup, and time-decay search</name>
  <files>nexus/packages/memory/src/index.ts</files>
  <action>
Modify the existing memory service (`nexus/packages/memory/src/index.ts`) to add three capabilities:

**1. memory_sessions table and session binding:**
Add a new SQLite table to the schema initialization:
```sql
CREATE TABLE IF NOT EXISTS memory_sessions (
  id TEXT PRIMARY KEY,
  session_id TEXT NOT NULL,
  memory_id TEXT NOT NULL,
  created_at INTEGER NOT NULL
);
CREATE INDEX IF NOT EXISTS idx_memory_sessions_session ON memory_sessions(session_id);
CREATE INDEX IF NOT EXISTS idx_memory_sessions_memory ON memory_sessions(memory_id);
```

Update the `/add` endpoint to accept an optional `sessionId` field in the request body. When provided, after inserting the memory, also insert a row into `memory_sessions` linking the session to the new memory. Use `generateId()` prefixed with `ms_` for the memory_session id.

Add a new endpoint `GET /sessions/:sessionId/memories` that returns all memories linked to a given session, ordered by created_at DESC.

**2. Deduplication via embedding similarity:**
Add a constant `DEDUP_THRESHOLD = 0.92` at the top of the file.

Before inserting a new memory in the `/add` endpoint, if an embedding was generated for the new content:
- Fetch the last 50 memories for the same userId that have embeddings
- Compute cosine similarity between the new embedding and each existing embedding
- If any existing memory has similarity >= DEDUP_THRESHOLD:
  - Instead of creating a new memory, update the existing memory's `content` to the new content (newer phrasing), update `updated_at` to now
  - Log: `[Memory] Dedup: merged with existing memory ${existingId} (similarity: ${score.toFixed(3)})`
  - Return `{ success: true, id: existingId, deduplicated: true }`
- If no match found, proceed with normal insert

**3. Time-decay scoring in search:**
In the `/search` endpoint, after computing cosine similarity scores, apply a time-decay factor:
```typescript
const AGE_DECAY_HALF_LIFE_DAYS = 30; // Memories lose half their boost every 30 days
const nowMs = Date.now();
const decayFactor = Math.pow(0.5, (nowMs - m.created_at) / (AGE_DECAY_HALF_LIFE_DAYS * 86400000));
const finalScore = score * 0.7 + decayFactor * 0.3; // 70% relevance, 30% recency
```
Use `finalScore` for sorting instead of raw cosine similarity. This ensures recent memories are prioritized when relevance is similar.

Also update the text-search fallback path to include time-decay scoring (sort by created_at DESC already gives recency, but assign `score` values that decay: `score = 0.5 * decayFactor`).

Do NOT change the existing imports, server setup, Redis connection, or the health/stats/reset/delete endpoints. Keep backward compatibility — the `sessionId` field is optional.
  </action>
  <verify>
Run `cd nexus/packages/memory && npx tsc --noEmit` to verify TypeScript compiles without errors. Grep for `memory_sessions`, `DEDUP_THRESHOLD`, and `AGE_DECAY_HALF_LIFE_DAYS` to confirm all three features are present.
  </verify>
  <done>
Memory service has: (1) memory_sessions table with session binding on /add, (2) deduplication that prevents same-fact entries above 0.92 similarity, (3) time-decay scoring in search that weights recency at 30%. TypeScript compiles cleanly.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add BullMQ memory extraction job triggered after conversation completion</name>
  <files>nexus/packages/core/src/daemon.ts, nexus/packages/core/src/index.ts</files>
  <action>
Add automatic memory extraction that runs as a BullMQ job after each conversation (agent task) completes.

**In `nexus/packages/core/src/daemon.ts`:**

1. Add import at top: `import { Queue, Worker } from 'bullmq';`

2. In the DaemonConfig interface (near the top), add:
   ```typescript
   memoryExtractionQueue?: Queue;
   ```

3. Find where the agent finishes processing an inbox item (the `processInboxItem` method or equivalent — look for where `agent.run()` returns and the response is sent). After the response is sent, enqueue a memory extraction job:
   ```typescript
   // After successful agent response
   if (this.config.memoryExtractionQueue) {
     const sessionId = `session_${item.from || 'web'}_${Date.now()}`;
     this.config.memoryExtractionQueue.add('extract-memories', {
       conversation: task.slice(0, 4000), // User message
       response: result.answer.slice(0, 4000), // AI response
       userId: item.from || 'default',
       sessionId,
       source: item.source || 'web',
     }, {
       removeOnComplete: { count: 100 },
       removeOnFail: { count: 50 },
     }).catch(err => logger.error('Failed to enqueue memory extraction', { error: err.message }));
   }
   ```

4. Add the extraction prompt as a constant near the other prompt constants (COMPLEXITY_PROMPT etc.) in daemon.ts:
   ```typescript
   const MEMORY_EXTRACTION_PROMPT = `Extract important facts, preferences, and knowledge from this conversation that would be useful to remember for future interactions. Return a JSON array of memory strings. Only include genuinely useful information — not greetings, acknowledgments, or task mechanics.

Examples of good memories:
- "User prefers dark mode"
- "User's server runs Ubuntu 22.04"
- "User's timezone is Europe/Istanbul"
- "The PostgreSQL password was changed on 2026-02-15"

Return ONLY a JSON array of strings. If nothing worth remembering, return [].

Conversation:`;
   ```

**In `nexus/packages/core/src/index.ts`:**

1. Add import: `import { Queue, Worker } from 'bullmq';`

2. After the `scheduleManager` initialization (around line 71), create the memory extraction queue and worker:
   ```typescript
   // Memory extraction queue
   const redisOpts = redis.options as any;
   const bullConnection = {
     host: redisOpts?.host || 'localhost',
     port: redisOpts?.port || 6379,
     ...(redisOpts?.password ? { password: redisOpts.password } : {}),
   };

   const memoryExtractionQueue = new Queue('nexus-memory-extraction', {
     connection: bullConnection,
     defaultJobOptions: {
       removeOnComplete: { count: 100 },
       removeOnFail: { count: 50 },
     },
   });

   const memoryExtractionWorker = new Worker(
     'nexus-memory-extraction',
     async (job) => {
       const { conversation, response, userId, sessionId, source } = job.data;
       try {
         // Use flash tier for cheap extraction
         const extractionResult = await brain.think({
           prompt: `${conversation}\n\nAssistant: ${response}`,
           systemPrompt: MEMORY_EXTRACTION_PROMPT,
           tier: 'flash',
           maxTokens: 500,
         });

         // Parse JSON array from response
         const cleaned = extractionResult.replace(/^```(?:json)?\s*/m, '').replace(/\s*```\s*$/m, '').trim();
         let memories: string[];
         try {
           memories = JSON.parse(cleaned);
         } catch {
           // Try to extract array from response
           const match = cleaned.match(/\[[\s\S]*\]/);
           memories = match ? JSON.parse(match[0]) : [];
         }

         if (!Array.isArray(memories) || memories.length === 0) {
           logger.debug('Memory extraction: nothing to remember', { sessionId });
           return;
         }

         // Store each extracted memory via memory service
         for (const content of memories.slice(0, 5)) { // Max 5 memories per conversation
           if (typeof content !== 'string' || content.length < 5) continue;
           try {
             await fetch('http://localhost:3300/add', {
               method: 'POST',
               headers: {
                 'Content-Type': 'application/json',
                 'X-API-Key': process.env.LIV_API_KEY || '',
               },
               body: JSON.stringify({
                 userId,
                 content,
                 sessionId,
                 metadata: { source, extractedAt: Date.now(), auto: true },
               }),
             });
           } catch (err: any) {
             logger.error('Memory extraction: failed to store', { error: err.message, content: content.slice(0, 50) });
           }
         }

         logger.info('Memory extraction complete', { sessionId, memoriesStored: memories.length });
       } catch (err: any) {
         logger.error('Memory extraction job failed', { error: err.message, sessionId });
       }
     },
     { connection: bullConnection, concurrency: 2 },
   );

   memoryExtractionWorker.on('failed', (job, err) => {
     logger.error('Memory extraction worker: job failed', { jobId: job?.id, error: err.message });
   });
   ```

3. You will need to import `MEMORY_EXTRACTION_PROMPT` from daemon.ts. Instead, define the prompt directly in index.ts above the worker definition. This avoids circular dependencies.

4. Pass `memoryExtractionQueue` to the Daemon config object:
   ```typescript
   const daemon = new Daemon({
     // ... existing fields
     memoryExtractionQueue,
   });
   ```

5. Add cleanup in the SIGTERM/SIGINT handler (or at the end of main if there is one):
   ```typescript
   // In graceful shutdown
   await memoryExtractionWorker.close();
   await memoryExtractionQueue.close();
   ```

**Important constraints:**
- Do NOT import from daemon.ts in index.ts (avoid circular deps). Define the prompt constant in index.ts.
- The memory extraction is fire-and-forget from the daemon's perspective — it must not slow down response delivery.
- Use `brain.think()` with `tier: 'flash'` for cheap extraction — this is a background task.
- The worker runs in the same process as the core daemon (not a separate service).
  </action>
  <verify>
Run `cd nexus/packages/core && npx tsc --noEmit` to verify TypeScript compiles. Grep for `nexus-memory-extraction` in index.ts and `memoryExtractionQueue` in daemon.ts to confirm the pipeline is wired.
  </verify>
  <done>
After each agent conversation completes, a BullMQ job is enqueued that: (1) sends the conversation to Brain flash tier for fact extraction, (2) parses the JSON array of memory strings, (3) stores each via the memory service /add endpoint with sessionId for session binding. The extraction runs in the background without blocking response delivery.
  </done>
</task>

</tasks>

<verification>
1. `cd nexus/packages/memory && npx tsc --noEmit` — zero errors
2. `cd nexus/packages/core && npx tsc --noEmit` — zero errors
3. Grep confirms `memory_sessions` table exists in memory service
4. Grep confirms `DEDUP_THRESHOLD` constant exists
5. Grep confirms `AGE_DECAY_HALF_LIFE_DAYS` constant exists
6. Grep confirms `nexus-memory-extraction` queue exists in index.ts
7. Grep confirms `memoryExtractionQueue` is passed to Daemon config
</verification>

<success_criteria>
- Memory service creates memory_sessions table on startup
- POST /add accepts optional sessionId and creates session link
- POST /add deduplicates memories above 0.92 cosine similarity
- POST /search applies 70/30 relevance/recency scoring
- After agent conversations, a BullMQ job extracts and stores memories automatically
- All TypeScript compiles cleanly
</success_criteria>

<output>
After completion, create `.planning/phases/v1.5-03-hybrid-memory-channel-expansion/v1.5-03-01-SUMMARY.md`
</output>
