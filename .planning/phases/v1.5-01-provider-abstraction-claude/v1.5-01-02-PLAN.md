---
phase: v1.5-01-provider-abstraction-claude
plan: 02
type: execute
wave: 2
depends_on: ["v1.5-01-01"]
files_modified:
  - nexus/packages/core/src/providers/claude.ts
  - nexus/packages/core/src/providers/index.ts
autonomous: true
user_setup:
  - service: anthropic
    why: "Claude API access for primary AI provider"
    env_vars:
      - name: ANTHROPIC_API_KEY
        source: "console.anthropic.com -> API Keys -> Create Key (sk-ant-api03-... format)"

must_haves:
  truths:
    - "ClaudeProvider can send a non-streaming chat request and return text + token usage"
    - "ClaudeProvider can stream text chunks that match the ProviderStreamChunk shape"
    - "ClaudeProvider maps model tiers correctly (flash->haiku-4-5, sonnet->sonnet-4-5, opus->opus-4-6)"
    - "ClaudeProvider reads API key from Redis (nexus:config:anthropic_api_key) with env fallback"
    - "ClaudeProvider returns false from isAvailable() when no API key is configured"
    - "Claude message format compliance is enforced (strict alternation via normalization layer)"
  artifacts:
    - path: "nexus/packages/core/src/providers/claude.ts"
      provides: "ClaudeProvider implementing AIProvider interface with streaming, chat, think, isAvailable"
      exports: ["ClaudeProvider"]
      min_lines: 120
  key_links:
    - from: "nexus/packages/core/src/providers/claude.ts"
      to: "@anthropic-ai/sdk"
      via: "import Anthropic from '@anthropic-ai/sdk'"
      pattern: "import Anthropic"
    - from: "nexus/packages/core/src/providers/claude.ts"
      to: "nexus/packages/core/src/providers/types.ts"
      via: "implements AIProvider"
      pattern: "implements AIProvider"
    - from: "nexus/packages/core/src/providers/claude.ts"
      to: "nexus/packages/core/src/providers/normalize.ts"
      via: "uses prepareForProvider for message format conversion"
      pattern: "prepareForProvider.*claude"
    - from: "nexus/packages/core/src/providers/claude.ts"
      to: "Redis nexus:config:anthropic_api_key"
      via: "redis.get for API key retrieval"
      pattern: "nexus:config:anthropic_api_key"
---

<objective>
Implement ClaudeProvider -- the primary AI provider for LivOS -- using @anthropic-ai/sdk.

Purpose: This is the core deliverable of the v1.5 migration. ClaudeProvider implements the AIProvider interface from Plan 01, providing chat(), chatStream(), think(), and isAvailable() methods. It maps Claude's streaming events (content_block_delta, message_stop) to the ProviderStreamChunk format so the existing AgentEvent SSE contract is preserved.

Note: This plan covers Redis storage and env fallback for API key retrieval only. The Settings UI for API key entry is handled by AUTH-01 in Phase 2 (v1.5-02).

Output: A fully functional ClaudeProvider that can be used by ProviderManager (Plan 03) as the primary provider.
</objective>

<execution_context>
@C:\Users\hello\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\hello\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/research/STACK.md
@.planning/research/PITFALLS.md

# Plan 01 outputs (types and normalization)
@.planning/phases/v1.5-01-provider-abstraction-claude/v1.5-01-01-SUMMARY.md

# Current Brain for understanding the interface contract
@nexus/packages/core/src/brain.ts

# Provider types from Plan 01
@nexus/packages/core/src/providers/types.ts
@nexus/packages/core/src/providers/normalize.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Upgrade @anthropic-ai/sdk and implement ClaudeProvider</name>
  <files>nexus/packages/core/src/providers/claude.ts</files>
  <action>
First, upgrade the Anthropic SDK:
```bash
cd nexus && npm install @anthropic-ai/sdk@latest
```
Verify the installed version is >= 0.74.0 (needed for messages.stream() helper).

Then create `nexus/packages/core/src/providers/claude.ts`:

```typescript
import Anthropic from '@anthropic-ai/sdk';
import type { Redis } from 'ioredis';
import type { AIProvider, ProviderChatOptions, ProviderChatResult, ProviderStreamResult, ProviderStreamChunk, ModelTier } from './types.js';
import { prepareForProvider, mergeConsecutiveRoles, normalizeMessages } from './normalize.js';
import { logger } from '../logger.js';
```

**CLAUDE_MODELS mapping:**
```typescript
const CLAUDE_MODELS: Record<string, string> = {
  flash: 'claude-haiku-4-5',
  haiku: 'claude-haiku-4-5',
  sonnet: 'claude-sonnet-4-5',
  opus: 'claude-opus-4-6',
};
```

**Class structure:**
```typescript
export class ClaudeProvider implements AIProvider {
  readonly id = 'claude';
  readonly supportsVision = true;
  readonly supportsToolCalling = true;

  private client: Anthropic | null = null;
  private redis: Redis | null = null;
  private cachedApiKey: string = '';

  constructor(redis?: Redis) { ... }
```

**API key retrieval (getClient method):**
- Read from Redis key `nexus:config:anthropic_api_key` first
- Fallback to `process.env.ANTHROPIC_API_KEY`
- Cache the client instance, re-create only if key changes
- If no key available, throw Error('No Anthropic API key configured')
- Note: This plan covers Redis storage and env fallback only. The Settings UI for entering/managing the API key is handled by AUTH-01 in Phase 2 (v1.5-02).

**chat() method:**
- Get tier model name from CLAUDE_MODELS (default to 'sonnet')
- Use `prepareForProvider(messages, 'claude')` to convert messages to Claude format
- Call `client.messages.create({ model, max_tokens, system: systemPrompt, messages: claudeMessages })`
- Extract text from response content blocks (concatenate all text blocks)
- Return `{ text, inputTokens: response.usage.input_tokens, outputTokens: response.usage.output_tokens, provider: 'claude', model }`
- Default max_tokens: 4096 (NOT 2048 -- Claude tool responses need more space, as noted in Pitfall #11)

**chatStream() method -- EXACT streaming implementation:**
- Use `client.messages.stream({ model, max_tokens, system: systemPrompt, messages: claudeMessages })` which returns a `MessageStream`
- Create an async generator that iterates the stream using `for await (const event of stream)`:

```typescript
chatStream(options: ProviderChatOptions): ProviderStreamResult {
  const tier = options.tier || 'sonnet';
  const model = CLAUDE_MODELS[tier] || CLAUDE_MODELS.sonnet;
  const maxTokens = options.maxOutputTokens || 4096;
  const claudeMessages = prepareForProvider(options.messages, 'claude');

  let finalInputTokens = 0;
  let finalOutputTokens = 0;
  const client = this; // for getClient() access in generator

  async function* generate(): AsyncGenerator<ProviderStreamChunk> {
    const anthropic = await client.getClient();
    const stream = anthropic.messages.stream({
      model,
      max_tokens: maxTokens,
      system: options.systemPrompt,
      messages: claudeMessages,
    });

    try {
      for await (const event of stream) {
        if (
          event.type === 'content_block_delta' &&
          event.delta.type === 'text_delta'
        ) {
          yield { text: event.delta.text, done: false };
        }
      }

      // After stream completes, get final usage from the accumulated message
      const finalMessage = await stream.finalMessage();
      finalInputTokens = finalMessage.usage.input_tokens;
      finalOutputTokens = finalMessage.usage.output_tokens;

      yield { text: '', done: true };
    } catch (err: any) {
      logger.error('ClaudeProvider.chatStream error', { error: err.message });
      yield { text: '', done: true };
      throw err;
    }
  }

  return {
    stream: generate(),
    getUsage: () => ({ inputTokens: finalInputTokens, outputTokens: finalOutputTokens }),
    provider: 'claude',
    model,
  };
}
```

Key points about this streaming pattern:
- `for await (const event of stream)` iterates over `MessageStreamEvent` objects
- Each event has a `type` field. We only care about `content_block_delta` events
- Within those, `event.delta.type === 'text_delta'` contains the actual text in `event.delta.text`
- Other event types (message_start, content_block_start, content_block_stop, message_stop, message_delta) are ignored
- After the for-await loop completes, `stream.finalMessage()` returns the complete Message with usage stats
- On error, yield a done chunk first so consumers don't hang, then re-throw for caller retry logic

**think() method:**
- Simple single-turn completion
- Create a single user message with the prompt
- Call `chat()` with the prompt wrapped as a single-message conversation
- Return just the text string

**isAvailable() method:**
- Try to read API key from Redis then env
- Return true if a key exists (don't make an API call, just check key presence)
- Wrap in try/catch, return false on any error

**getModels() method:**
- Return the CLAUDE_MODELS record

**Retry handling:**
- Do NOT implement retry inside ClaudeProvider -- the Brain wrapper and AgentLoop already have retry logic
- ClaudeProvider should throw on errors and let callers handle retries
- Use the existing `retryAsync` and `isRetryableError` infrastructure from `../infra/retry.js` and `../infra/errors.js`
  </action>
  <verify>
1. `cd nexus && npx tsc --noEmit --pretty 2>&1 | head -30` -- no TypeScript errors
2. `grep -c 'claude-' nexus/packages/core/src/providers/claude.ts` confirms model names present
3. `grep 'implements AIProvider' nexus/packages/core/src/providers/claude.ts` confirms interface implementation
4. `grep 'anthropic_api_key' nexus/packages/core/src/providers/claude.ts` confirms Redis key usage
5. `npm ls @anthropic-ai/sdk` in nexus/ shows version >= 0.74.0
6. `grep 'content_block_delta' nexus/packages/core/src/providers/claude.ts` confirms exact streaming event check
7. `grep 'text_delta' nexus/packages/core/src/providers/claude.ts` confirms text delta extraction
  </verify>
  <done>
ClaudeProvider implements AIProvider with: chat() using messages.create(), chatStream() using messages.stream() with async generator that iterates events via `for await`, checks `event.type === 'content_block_delta'` and `event.delta.type === 'text_delta'`, extracts `event.delta.text`, and gets final usage from `stream.finalMessage()`. think() for simple completions, isAvailable() checking API key presence. Model tier mapping: flash/haiku -> claude-haiku-4-5, sonnet -> claude-sonnet-4-5, opus -> claude-opus-4-6. API key read from Redis `nexus:config:anthropic_api_key` with ANTHROPIC_API_KEY env fallback. SDK upgraded to latest version. Settings UI for API key management is deferred to Phase 2 (AUTH-01).
  </done>
</task>

<task type="auto">
  <name>Task 2: Update barrel export and verify compilation</name>
  <files>nexus/packages/core/src/providers/index.ts</files>
  <action>
Update the barrel export at `nexus/packages/core/src/providers/index.ts` to include ClaudeProvider:

```typescript
export * from './types.js';
export * from './normalize.js';
export { ClaudeProvider } from './claude.js';
```

Then run a full TypeScript compilation check to ensure no errors across the entire nexus package:
```bash
cd nexus && npx tsc --noEmit
```

If there are errors related to the new @anthropic-ai/sdk version (e.g., type changes from 0.39 to latest), fix them. Common issues:
- The SDK default import pattern may differ: it should be `import Anthropic from '@anthropic-ai/sdk'`
- Message type names may have changed between SDK versions
- The `stream()` method may have a slightly different signature

Fix any issues until `tsc --noEmit` passes cleanly.
  </action>
  <verify>
`cd nexus && npx tsc --noEmit --pretty` exits with code 0 (no errors). `grep 'ClaudeProvider' nexus/packages/core/src/providers/index.ts` confirms export.
  </verify>
  <done>
The providers/ barrel exports types, normalize, and ClaudeProvider. The entire nexus package compiles without TypeScript errors. The @anthropic-ai/sdk upgrade does not break existing code (the old SDK was imported but never used in source).
  </done>
</task>

</tasks>

<verification>
1. `cd nexus && npx tsc --noEmit` passes cleanly
2. `npm ls @anthropic-ai/sdk` shows version >= 0.74.0
3. ClaudeProvider has all AIProvider methods: chat, chatStream, think, isAvailable, getModels
4. chatStream uses `for await (const event of stream)` with `event.type === 'content_block_delta'` and `event.delta.type === 'text_delta'`
5. chatStream extracts text via `event.delta.text` and gets usage via `stream.finalMessage()`
6. Model tier mapping matches research: flash->haiku-4-5, sonnet->sonnet-4-5, opus->opus-4-6
7. API key sourced from Redis then env (same pattern as existing Gemini key)
8. Message format uses prepareForProvider('claude') from the normalization layer
9. Settings UI for API key entry is explicitly deferred to Phase 2 (AUTH-01)
</verification>

<success_criteria>
- ClaudeProvider compiles and implements the full AIProvider interface
- Streaming uses the SDK's messages.stream() with for-await iteration over MessageStreamEvent, checking content_block_delta + text_delta
- Model mapping is correct per the research tier table
- API key retrieval follows the Redis-first, env-fallback pattern
- No TypeScript compilation errors in the nexus package
- The @anthropic-ai/sdk is upgraded to the latest version
</success_criteria>

<output>
After completion, create `.planning/phases/v1.5-01-provider-abstraction-claude/v1.5-01-02-SUMMARY.md`
</output>
