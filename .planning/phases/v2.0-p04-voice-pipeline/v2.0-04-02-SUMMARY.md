# Phase 4 Plan 02: Deepgram STT Integration Summary

**One-liner:** DeepgramRelay class with persistent WebSocket to Deepgram STT, wired into VoiceSession for real-time transcript streaming + daemon.addToInbox() for AI processing

## What Was Done

### Task 1: DeepgramRelay class — persistent STT WebSocket
- Created `nexus/packages/core/src/voice/deepgram-relay.ts` (288 lines):
  - `DeepgramRelayConfig` interface with model, language, encoding, sampleRate, channels, interimResults, punctuate, endpointing, utteranceEndMs
  - `DeepgramTranscript` interface with text, isFinal, confidence, speechFinal, timestamp
  - `DeepgramRelay` class extending EventEmitter
  - Connects to `wss://api.deepgram.com/v1/listen` with query params and Token auth header
  - `send(audioChunk)` relays binary audio frames to Deepgram
  - Parses Deepgram Results messages, extracts transcript text/confidence/is_final/speech_final
  - Emits `'transcript'`, `'error'`, `'close'`, `'open'` events
  - Exponential backoff reconnection: 5 attempts at 100, 500, 1000, 2000, 5000ms
  - Graceful `close()` sends CloseStream JSON before WebSocket close

### Task 2: Wire DeepgramRelay into VoiceSession + daemon.addToInbox()
- Updated `nexus/packages/core/src/voice/voice-session.ts`:
  - Added `deepgramApiKey`, `sttModel`, `sttLanguage`, `onTranscript` to VoiceSessionOpts
  - Added private `sttRelay: DeepgramRelay | null` field
  - `startListening()`: Creates DeepgramRelay, wires transcript events, connects, transitions to 'listening'
  - `handleBinaryMessage()`: Relays audio to sttRelay.send() when in listening state
  - `stopListening()`: Closes sttRelay, transitions to 'processing' (if transcript received) or 'idle'
  - All transcripts sent to browser via sendControl() for real-time visual feedback
  - speechFinal transcripts trigger onTranscript callback -> daemon.addToInbox()
  - Error handling: sends error control message if no Deepgram API key
  - `close()`: Cleans up sttRelay
- Updated `nexus/packages/core/src/voice/index.ts`:
  - Added `voiceConfig?: VoiceConfig` to VoiceGatewayDeps
  - Passes deepgramApiKey, sttModel, sttLanguage from voiceConfig to VoiceSession
  - onTranscript callback calls `daemon.addToInbox(text, 'voice' as any, ..., { voiceSessionId })`
- Updated `nexus/packages/core/src/index.ts`:
  - Passes `voiceConfig: configManager.get().voice` to VoiceGateway constructor
  - Enhanced log with enabled/hasDeepgramKey info

## Commits

| # | Hash | Message |
|---|------|---------|
| 1 | e3d85e9 | feat(v2.0-04-02): DeepgramRelay class — persistent STT WebSocket |
| 2 | 6d43dd0 | feat(v2.0-04-02): wire DeepgramRelay into VoiceSession + daemon.addToInbox() |

## Verification Results

1. TypeScript compiles: `npx tsc --noEmit` passes with zero errors
2. DeepgramRelay connects to correct endpoint: `wss://api.deepgram.com/v1/listen` confirmed
3. Audio relay chain: VoiceSession.handleBinaryMessage -> sttRelay.send() -> Deepgram WebSocket
4. Transcript chain: Deepgram -> sttRelay 'transcript' event -> VoiceSession -> browser (control msg) + daemon.addToInbox()
5. State transitions: idle->listening (STT connect) -> processing (utterance complete)
6. Reconnection: DeepgramRelay handles disconnect with exponential backoff (max 5 attempts)

## Deviations from Plan

None -- plan executed exactly as written.

## Files

### Created
- `nexus/packages/core/src/voice/deepgram-relay.ts` (288 lines)

### Modified
- `nexus/packages/core/src/voice/voice-session.ts` (+115 lines: STT integration, startListening/stopListening/closeSttRelay)
- `nexus/packages/core/src/voice/index.ts` (+18 lines: voiceConfig deps, onTranscript callback)
- `nexus/packages/core/src/index.ts` (+3 lines: voiceConfig passthrough, enhanced logging)

## Decisions Made

| Decision | Context | Choice |
|----------|---------|--------|
| Voice source type | How to type 'voice' in Intent source union | Use `as any` cast — Intent union update deferred to avoid touching router.ts |
| Transcript trigger | When to send transcript to daemon | On speechFinal (complete utterance), not just isFinal (end of interim segment) |
| Stop-listening behavior | What state to transition to on stop | 'processing' if transcript received, 'idle' if no transcript |
| Deepgram auth | How to authenticate with Deepgram API | Token header (Authorization: Token KEY) — more secure than query param |

## Duration

~3 minutes (2026-02-20T23:54:53Z to 2026-02-20T23:57:56Z)

## Next Phase Readiness

Plan 03 (TTS integration) can proceed immediately:
- VoiceSession has `sendAudio()` for binary TTS output to browser
- VoiceSession transitions processing->speaking->idle for TTS lifecycle
- Config schema has `cartesiaApiKey`, `cartesiaVoiceId`, `cartesiaModelId` fields ready
- State machine is processing->speaking transition ready for TTS audio delivery

Plan 04 (UI voice widget) can proceed after Plan 03:
- Browser receives `{ type: 'transcript', text, isFinal, confidence }` control messages for display
- Browser receives `{ type: 'error', message }` for error display
- Binary audio frames (TTS) will be sent as binary WebSocket messages
