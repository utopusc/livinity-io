---
phase: v2.0-p04-voice-pipeline
plan: 02
type: execute
wave: 2
depends_on: ["v2.0-04-01"]
files_modified:
  - nexus/packages/core/src/voice/deepgram-relay.ts
  - nexus/packages/core/src/voice/voice-session.ts
  - nexus/packages/core/src/voice/index.ts
  - nexus/packages/core/src/index.ts
autonomous: true

must_haves:
  truths:
    - "Audio from the browser microphone is relayed to Deepgram's real-time STT WebSocket"
    - "Deepgram returns transcript text which is fed to the AI agent via daemon.addToInbox()"
    - "Deepgram connection is persistent per VoiceSession and reconnects on failure"
    - "Interim (partial) transcripts are sent to the browser for visual feedback"
    - "Final transcript triggers AI processing and VoiceSession transitions to 'processing' state"
  artifacts:
    - path: "nexus/packages/core/src/voice/deepgram-relay.ts"
      provides: "DeepgramRelay class — persistent WebSocket to Deepgram STT, audio relay, transcript parsing"
      min_lines: 120
  key_links:
    - from: "nexus/packages/core/src/voice/voice-session.ts"
      to: "nexus/packages/core/src/voice/deepgram-relay.ts"
      via: "VoiceSession creates DeepgramRelay, pipes audio-in events to relay.send()"
      pattern: "DeepgramRelay"
    - from: "nexus/packages/core/src/voice/deepgram-relay.ts"
      to: "daemon.addToInbox"
      via: "Final transcript callback invokes daemon.addToInbox() with source 'voice'"
      pattern: "addToInbox"
---

<objective>
Integrate Deepgram real-time STT into the voice pipeline. Browser audio flows through VoiceSession to DeepgramRelay, which relays it to Deepgram's WebSocket API. Transcripts flow back and trigger AI agent processing via daemon.addToInbox().

Purpose: This is the "ears" of the voice pipeline. Without STT, spoken words cannot become text for the AI to process.

Output: DeepgramRelay class, VoiceSession STT wiring, daemon inbox integration for voice transcripts.
</objective>

<execution_context>
@C:\Users\hello\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\hello\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/v2.0-p04-voice-pipeline/v2.0-04-01-SUMMARY.md

Key reference files:
@nexus/packages/core/src/voice/voice-session.ts — VoiceSession state machine (created in Plan 01)
@nexus/packages/core/src/voice/index.ts — VoiceGateway (created in Plan 01)
@nexus/packages/core/src/daemon.ts — addToInbox() method for feeding voice transcripts to the AI
@nexus/packages/core/src/config/schema.ts — VoiceConfig with deepgramApiKey, sttLanguage, sttModel
</context>

<tasks>

<task type="auto">
  <name>Task 1: DeepgramRelay class — persistent STT WebSocket</name>
  <files>
    nexus/packages/core/src/voice/deepgram-relay.ts
  </files>
  <action>
1. **Create nexus/packages/core/src/voice/deepgram-relay.ts:**

   Deepgram's real-time STT API uses a WebSocket at `wss://api.deepgram.com/v1/listen`. Authentication is via query param `token=API_KEY` or `Authorization: Token API_KEY` header.

   - Import `WebSocket` from 'ws', `EventEmitter` from 'events', `logger` from '../logger.js'.

   - Define `DeepgramRelayConfig`:
     ```typescript
     interface DeepgramRelayConfig {
       apiKey: string;
       model?: string;       // default 'nova-3'
       language?: string;     // default 'en'
       encoding?: string;     // default 'linear16'
       sampleRate?: number;   // default 16000
       channels?: number;     // default 1
       interimResults?: boolean; // default true
       punctuate?: boolean;   // default true
       endpointing?: number;  // default 300 (ms of silence before final)
       utteranceEndMs?: number; // default 1000 (gap between utterances)
     }
     ```

   - Define `DeepgramTranscript`:
     ```typescript
     interface DeepgramTranscript {
       text: string;
       isFinal: boolean;
       confidence: number;
       speechFinal: boolean;  // End of utterance (not just end of interim)
       timestamp: number;     // When received
     }
     ```

   - Implement `DeepgramRelay` class extending `EventEmitter`:
     - Events: `'transcript'`, `'error'`, `'close'`, `'open'`.
     - Constructor takes `DeepgramRelayConfig`.
     - Private fields: `ws: WebSocket | null`, `config`, `reconnectAttempts: number`, `maxReconnectAttempts: 5`, `reconnectBackoff: number[]` (100, 500, 1000, 2000, 5000ms), `isClosing: boolean`.

     - `connect()`: Build WebSocket URL:
       ```
       wss://api.deepgram.com/v1/listen?model=${model}&language=${language}&encoding=${encoding}&sample_rate=${sampleRate}&channels=${channels}&interim_results=${interimResults}&punctuate=${punctuate}&endpointing=${endpointing}&utterance_end_ms=${utteranceEndMs}
       ```
       - Create WebSocket with header `{ Authorization: 'Token ' + this.config.apiKey }`.
       - `ws.on('open')`: Reset reconnect attempts, emit 'open', log info.
       - `ws.on('message')`: Parse JSON. Deepgram sends:
         ```json
         {
           "type": "Results",
           "channel": { "alternatives": [{ "transcript": "hello world", "confidence": 0.98 }] },
           "is_final": true,
           "speech_final": true
         }
         ```
         Extract transcript text, confidence, is_final, speech_final. If transcript is non-empty, emit `'transcript'` event with `DeepgramTranscript`.
       - `ws.on('close')`: If not `isClosing`, attempt reconnect with backoff.
       - `ws.on('error')`: Log error, emit 'error'.

     - `send(audioChunk: Buffer)`: If ws is open (readyState === OPEN), send binary frame. Otherwise log warning and drop.

     - `reconnect()`: If attempts < max, wait backoff[attempts] ms, then call `connect()`. Increment attempts. Log reconnect attempt.

     - `close()`: Set `isClosing = true`. Send Deepgram close message `{ type: 'CloseStream' }` as JSON text, then `ws.close()`. Remove listeners.

     - `isConnected()`: Returns `ws?.readyState === WebSocket.OPEN`.

   - Export `DeepgramRelay`, `DeepgramRelayConfig`, `DeepgramTranscript`.
  </action>
  <verify>
    - `npx tsc --noEmit` passes.
    - DeepgramRelay exports are importable.
    - grep "wss://api.deepgram.com" confirms correct endpoint.
  </verify>
  <done>
    DeepgramRelay class connects to Deepgram's real-time STT WebSocket, relays binary audio, parses transcript events, and reconnects with exponential backoff on failure.
  </done>
</task>

<task type="auto">
  <name>Task 2: Wire DeepgramRelay into VoiceSession + daemon.addToInbox()</name>
  <files>
    nexus/packages/core/src/voice/voice-session.ts
    nexus/packages/core/src/voice/index.ts
    nexus/packages/core/src/index.ts
  </files>
  <action>
1. **Update VoiceSession to manage DeepgramRelay:**
   - Import `DeepgramRelay` from `./deepgram-relay.js`.
   - Add to constructor config: `deepgramApiKey?: string`, `sttModel?: string`, `sttLanguage?: string`.
   - Add private field: `sttRelay: DeepgramRelay | null = null`.
   - Add `onTranscript` callback in constructor config: `onTranscript: (sessionId: string, text: string) => void` — this is how the final transcript gets sent to the daemon.

   - **Modify `handleTextMessage` for `start-listening`:**
     When `{ type: 'start-listening' }` is received:
     - Check that `deepgramApiKey` exists. If not, send error control message: `{ type: 'error', message: 'Deepgram API key not configured' }`.
     - Create `DeepgramRelay` with config from constructor.
     - Wire `sttRelay.on('transcript', (t) => ...)`:
       - Send interim transcripts to browser: `this.sendControl({ type: 'transcript', text: t.text, isFinal: t.isFinal, confidence: t.confidence })`.
       - On `speechFinal === true` (end of complete utterance): Call `this.onTranscript(this.sessionId, t.text)`. Transition state to 'processing'.
     - Wire `sttRelay.on('error', ...)`: Send error to browser, log.
     - Call `sttRelay.connect()`.
     - Transition to 'listening'.

   - **Modify `handleBinaryMessage`:**
     When state is 'listening' and `sttRelay` exists, call `sttRelay.send(data)` to relay audio to Deepgram.

   - **Modify `handleTextMessage` for `stop-listening`:**
     When `{ type: 'stop-listening' }`: Close sttRelay, set to null. Transition to 'processing' (if any pending transcript) or 'idle' (if no transcript received).

   - **Update `close()`:** Close sttRelay if exists.

2. **Update VoiceGateway to pass config and daemon reference:**
   - Update `VoiceGatewayDeps` to include voice config:
     ```typescript
     export interface VoiceGatewayDeps {
       redis: Redis;
       daemon: Daemon;
       voiceConfig?: VoiceConfig; // From NexusConfig
     }
     ```
   - When creating VoiceSession on connection, pass:
     - `deepgramApiKey: deps.voiceConfig?.deepgramApiKey`
     - `sttModel: deps.voiceConfig?.sttModel`
     - `sttLanguage: deps.voiceConfig?.sttLanguage`
     - `onTranscript: (sessionId, text) => { deps.daemon.addToInbox(text, 'voice' as any, undefined, { voiceSessionId: sessionId }, sessionId); }`

   The `source: 'voice'` will need to be added to the Intent source type. For now use type assertion `as any` — this is acceptable since the daemon's addToInbox already uses `Intent['source']` which is a string union, and 'voice' will be recognized as a new channel source.

3. **Update index.ts to pass voice config to VoiceGateway:**
   - When creating VoiceGateway, pass `voiceConfig: configManager.get().voice`:
     ```typescript
     const voiceConfig = configManager.get().voice;
     const voiceGateway = new VoiceGateway(httpServer, {
       redis,
       daemon,
       voiceConfig,
     });
     logger.info('VoiceGateway initialized', { enabled: voiceConfig?.enabled, hasDeepgramKey: !!voiceConfig?.deepgramApiKey });
     ```
  </action>
  <verify>
    - `npx tsc --noEmit` passes.
    - VoiceSession constructor accepts deepgramApiKey and onTranscript callback.
    - grep "addToInbox" in voice/index.ts confirms daemon wiring.
    - grep "DeepgramRelay" in voice-session.ts confirms STT relay integration.
  </verify>
  <done>
    Browser audio flows through VoiceSession to DeepgramRelay to Deepgram STT. Transcripts flow back to browser (for display) and to daemon.addToInbox() (for AI processing). VoiceSession state transitions from listening to processing when a complete utterance is detected.
  </done>
</task>

</tasks>

<verification>
1. TypeScript compiles: `cd nexus/packages/core && npx tsc --noEmit` — zero errors.
2. DeepgramRelay connects to correct endpoint: grep "api.deepgram.com" confirms URL.
3. Audio relay chain: VoiceSession.handleBinaryMessage -> sttRelay.send() -> Deepgram WebSocket.
4. Transcript chain: Deepgram -> sttRelay 'transcript' event -> VoiceSession -> browser (control msg) + daemon.addToInbox().
5. State transitions: listening (audio flowing) -> processing (utterance complete).
6. Reconnection: DeepgramRelay handles disconnect with exponential backoff (max 5 attempts).
</verification>

<success_criteria>
- DeepgramRelay class connects to Deepgram STT WebSocket with proper authentication.
- Binary audio from browser is relayed to Deepgram without base64 encoding overhead.
- Interim transcripts are sent to browser for real-time display.
- Final/speech-final transcripts trigger daemon.addToInbox() with source 'voice'.
- DeepgramRelay reconnects automatically on connection failure.
- VoiceSession state machine transitions correctly through the STT flow.
</success_criteria>

<output>
After completion, create `.planning/phases/v2.0-p04-voice-pipeline/v2.0-04-02-SUMMARY.md`
</output>
