---
phase: v2.0-p03-intelligence-enhancements
plan: 01
subsystem: intelligence
tags: [session-compaction, context-management, token-optimization, redis]

dependency_graph:
  requires: [v2.0-p01-core-infrastructure]
  provides: [session-compaction, auto-compact, compact-command]
  affects: [v2.0-p03-03]

tech_stack:
  added: []
  patterns: [tiered-summarization, critical-fact-pinning, token-estimation, auto-compaction]

key_files:
  created: []
  modified:
    - nexus/packages/core/src/session-manager.ts
    - nexus/packages/core/src/commands.ts
    - nexus/packages/core/src/daemon.ts

decisions:
  - id: COMP-BRAIN-PARAM
    choice: "Brain passed as parameter to compactSession(), not stored on SessionManager"
    reason: "SessionManager only depends on Redis — keeps constructor simple"
  - id: COMP-TOKEN-ESTIMATE
    choice: "estimateTokenCount uses Math.ceil(text.length / 4) approximation"
    reason: "Standard ~4 chars/token for English; avoids tokenizer dependency"
  - id: COMP-THRESHOLD
    choice: "Auto-compact threshold: 100k tokens"
    reason: "Matches plan spec; prevents context window exhaustion while allowing long conversations"

metrics:
  duration: "6min"
  completed: "2026-02-20"
---

# Phase 3 Plan 01: Session Compaction Summary

**One-liner:** Session compaction with tiered summarization via Brain haiku, critical fact pinning, auto-compact at 100k tokens, and /compact command with token savings report.

## What Was Done

### Task 1: Implement compactSession() in SessionManager
**Commit:** `7fc8e25`

Added four new methods and one interface update to SessionManager:

- `estimateTokenCount(text)` — Approximates token count at ~4 chars/token
- `extractCriticalFacts(messages)` — Scans all messages for file paths (Unix + Windows), error codes, IP addresses, URLs, port numbers, and user preference statements. Returns `[PINNED]` tagged strings
- `compactSession(senderId, brain)` — Core compaction: splits history at last 10 messages, extracts critical facts from ALL messages, calls Brain.think() with haiku tier to summarize older messages, writes `[COMPACTED SUMMARY]` + `[CRITICAL FACTS]` + preserved messages back to Redis, updates session metadata with compaction count and savings
- `getSessionTokenCount(senderId)` — Returns estimated token count for full history (used by auto-compact threshold check)
- Added `compactedSummary?: string` to `SessionState` interface

### Task 2: Implement /compact command and auto-compact trigger
**Commit:** `09f49c5`

Commands.ts changes:
- Added `brain?: Brain` to `CommandContext` interface
- Replaced `handleCompact()` stub with full implementation that calls `compactSession()` and returns formatted savings report (messages compacted, original tokens, saved tokens with percentage)
- Updated help text to remove "(coming soon)" from /compact description

Daemon.ts changes:
- Added `brain: this.config.brain` to both `handleCommand()` call sites (cycle + processInboxItem)
- Added COMP-05 auto-compact block after usage tracking: checks `getSessionTokenCount()` > 100k, calls `compactSession()`, logs results

## Verification Results

| Check | Status |
|-------|--------|
| TypeScript compiles cleanly | PASS |
| compactSession() exists with (senderId, brain) params | PASS |
| /compact no longer returns "coming soon" | PASS |
| Auto-compact check in daemon after usage tracking | PASS |
| Brain passed as parameter, not stored | PASS |
| Critical fact extraction covers paths, errors, IPs, URLs, preferences | PASS |

## Deviations from Plan

None - plan executed exactly as written.

## Decisions Made

1. **Brain as parameter** — Brain is passed to `compactSession()` rather than stored on SessionManager, keeping SessionManager's only dependency as Redis
2. **Token estimation** — Using `Math.ceil(text.length / 4)` rather than an actual tokenizer to avoid adding a dependency
3. **Redis history replacement** — Compacted history replaces full history in the same Redis list key (no new keys needed), using del + lpush sequence

## Next Phase Readiness

Plan 03-01 provides session compaction that Plan 03-03 (sub-agent execution) may need for long multi-agent conversations. All COMP requirements (01-06) are satisfied.
